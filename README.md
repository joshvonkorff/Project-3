This project is an analysis of many presidential speeches from the site millercenter.org.  The site contains the text of at least one speech (and almost always more) given by each of the 44 presidents.

The goal is to cluster presidents into three clusters based on the words that they use in their speeches.  Words are given more weight if (1) they are frequent in that president's speeches, (2) they are more common in that president's speeches than in the English language generally.  Based on this weight function, presidents who use similar words are said to be similar and are grouped together.

The conclusion is that the three groups of presidents are more or less consecutive in time.  The first group runs from George Washington to Andrew Johnson; the second from Ulysses S. Grant to Herber Hoover; and the third from Franklin D. Roosevelt to Donald Trump.

Based on the weight function, we can calculate

The "weight" for each word is calculated as follows. The goal is to have a weight that reflects (1) the relative incidence of the word in the speech corpus compared with its usual incidence in the English language, (2) the overall incidence of the word in the speech corpus. Thus, a word that is highly unusual ("supercalifragilisticexpealidocious") but only appears once in the speech corpus is not that interesting. In contrast, a word that is very common, but appears only the usual amount in the corpus ("the") is also not interesting. The weight for each words is computed as a product of these two factors.
Getting into the details: To compute the weight, the incidence count of the word is first tallied in the combined speeches of a president. Using the wordfreq library, each word's frequency in English is obtained (actually the log of the frequency), so that it can be compared with the log of the frequency in the speeches. Using the statsmodels library, a least squares regression is used to find the linear relationship between these two logs.
This linear relationship can then be used to compute the predicted English frequency for a word that has the given corpus frequency. This predicted English frequency can be compared to the word's actual English frequency. The difference between predicted and actual (using subtraction) is essentially a measure of how much more common the word is in the speech corpus compared to the English language. A weight value of 1 would mean that the word is "e" times more common in the speech corpus as compared with English.
Next, the number of words in each speech can range from 20,000 to 800,000, so the number of appearances is multiplied by (800,000 / length) to get the number that would appear in 800,000. Then, the log is taken. This number is multiplied by the weight to get the final weight value. This takes into account that we care more about words that appear many times as opposed to only once.
